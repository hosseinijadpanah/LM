{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Document Similarity Checker\n",
        "\n",
        "\n",
        "\n",
        "A \"Document Similarity Checker\" is a tool or system that assesses and quantifies the similarity between two or more documents or articles. The primary goal of such a tool is to determine how closely related or similar the content of these documents is to each other. This can have various applications in information retrieval, natural language processing, content recommendation, and more.\n",
        "\n",
        "\n",
        "\n",
        "Input Documents:\n",
        "\n",
        "The tool takes a set of input documents or articles as its primary input. These documents can be in various formats, such as text, PDFs, web pages, or any other structured or unstructured content.\n",
        "\n",
        "Textual Analysis:\n",
        "\n",
        "The tool typically performs textual analysis on the input documents. This involves preprocessing steps like **tokenization** (breaking text into words or phrases), **removing stop words** (common words like \"the,\" \"and,\" \"is\"), **stemming or lemmatization** (reducing words to their root forms), and possibly more advanced techniques like named entity recognition and part-of-speech tagging.\n",
        "\n",
        "Feature Extraction:\n",
        "\n",
        "After preprocessing, the tool extracts relevant features or representations from the documents. Common methods include:\n",
        "\n",
        "-** Bag of Words** (BoW): Representing each document as a vector of word frequencies.\n",
        "- **Term Frequency-Inverse Document Frequency (TF-IDF)**: Assigning weights to words based on their importance within a document and across a corpus of documents.\n",
        "\n",
        "- **Word Embeddings**: Converting words or phrases into dense vector representations using techniques like **Word2Vec or GloVe**.\n",
        "\n",
        "- **Doc2Vec**: Extending word embeddings to represent entire documents as vectors.\n",
        "- **BERT Embeddings**: Leveraging pre-trained transformer models like **BERT** to encode document content.\n",
        "\n",
        "\n",
        "\n",
        "Similarity Calculation:\n",
        "\n",
        "\n",
        "With feature vectors representing the documents, the tool calculates the similarity between pairs of documents. **Common similarity metrics include**:\n",
        "\n",
        "- **Cosine Similarit**y: Measures the cosine of the angle between two vectors. It's often used with **TF-IDF or word embeddings**.\n",
        "\n",
        "- **Jaccard Similarity**: Measures the intersection over the union of sets, typically used for binary representations like **BoW**.\n",
        "\n",
        "- **Euclidean** Distance: Measures the straight-line distance between vectors.\n",
        "\n",
        "- **Manhattan** Distance: Measures the sum of absolute differences between vector components.\n",
        "\n",
        "- **Pearson** **Correlation** **Coefficient**: Measures the linear correlation between two vectors.\n",
        "\n",
        "- **Kullback-Leibler Divergence**: Measures the difference between probability distributions.\n",
        "\n",
        "\n",
        "Similarity Scores:\n",
        "\n",
        "The tool produces similarity scores for pairs of documents. These scores range from 0 (completely dissimilar) to 1 (identical) or can have other scales depending on the chosen similarity metric.\n",
        "\n",
        "Applications:\n",
        "\n",
        "Document similarity checkers find applications in various domains:\n",
        "\n",
        "Information Retrieval: To retrieve documents similar to a query or search result.\n",
        "\n",
        "Plagiarism Detection: To identify instances of copied or closely paraphrased content.\n",
        "\n",
        "Content Recommendation: To suggest articles, products, or content similar to what a user has viewed or liked.\n",
        "\n",
        "Content Clustering: To group related documents for organization and analysis.\n",
        "Automated Summarization: To find similar articles for summarization or content consolidation.\n",
        "\n",
        "Document Classification: To assist in categorizing documents based on their similarity to predefined categories.\n",
        "\n",
        "Overall, a Document Similarity Checker is a valuable tool for analyzing and managing large collections of documents, making it easier to retrieve, classify, and recommend content based on its similarity to other documents of interest.\n",
        "\n",
        "a simple Python code for a Document Similarity Checker using **TF-IDF** (Term Frequency-Inverse Document Frequency) **with scikit-learn**. This code **calculates the cosine similarity between a set of short documents**.\n",
        "\n",
        "\n",
        "This code performs the following steps:\n",
        "\n",
        "- Defines a list of sample short documents.\n",
        "- Creates a TF-IDF vectorizer to convert the text into numerical vectors.\n",
        "- Fits and transforms the documents into TF-IDF vectors.\n",
        "- Calculates the cosine similarity between all pairs of documents.\n",
        "- Prints the cosine similarity matrix.\n",
        "- Prints the pairwise similarity scores between the documents."
      ],
      "metadata": {
        "id": "EwzsNxBknugQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8erlfTe-nuuB",
        "outputId": "3bb653e2-ee17-47a5-82f0-7e5ced2ff12e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Sample short documents\n",
        "documents = [\n",
        "    \"Document 1: This is a sample document about document similarity.\",\n",
        "    \"Document 2: Similarity checkers can help find related documents.\",\n",
        "    \"Document 3: Document analysis is important for natural language processing.\",\n",
        "]\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents into TF-IDF vectors\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Calculate cosine similarity between documents\n",
        "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Print the cosine similarity matrix\n",
        "print(\"Cosine Similarity Matrix:\")\n",
        "print(cosine_similarities)\n",
        "\n",
        "# Calculate and print pairwise similarity scores\n",
        "print(\"\\nPairwise Similarity Scores:\")\n",
        "for i in range(len(documents)):\n",
        "    for j in range(i + 1, len(documents)):\n",
        "        similarity_score = cosine_similarities[i][j]\n",
        "        print(f\"Similarity between Document {i + 1} and Document {j + 1}: {similarity_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9JU14rEqDqY",
        "outputId": "cf116463-3f88-4e46-f34d-91b1d781cc99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Matrix:\n",
            "[[1.         0.22855583 0.35022982]\n",
            " [0.22855583 1.         0.09387083]\n",
            " [0.35022982 0.09387083 1.        ]]\n",
            "\n",
            "Pairwise Similarity Scores:\n",
            "Similarity between Document 1 and Document 2: 0.2286\n",
            "Similarity between Document 1 and Document 3: 0.3502\n",
            "Similarity between Document 2 and Document 3: 0.0939\n"
          ]
        }
      ]
    }
  ]
}